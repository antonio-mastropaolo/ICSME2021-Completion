{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os, time, json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "def computeBleu1_to_4(reference_list, candidate_list, filename, i):\n",
    "    \n",
    "    bleu1_sum = bleu2_sum = bleu3_sum = bleu4_sum = bleuA_sum = 0\n",
    "        \n",
    "    for (ref, cand) in zip(reference_list, candidate_list):\n",
    "        \n",
    "        tokens_real = ref.split(' ')\n",
    "        tokens_pred = cand.split(' ')\n",
    "\n",
    "        if cand == '':\n",
    "            bleu1_score = bleu2_score = bleu3_score = bleu4_score = bleuA_score = 0\n",
    "            \n",
    "        else:\n",
    "            bleu1_score = sentence_bleu([tokens_real], tokens_pred, weights=(1.0, 0.0, 0.0, 0.0))\n",
    "            bleu2_score = sentence_bleu([tokens_real],tokens_pred, weights=(0.0, 1.0, 0.0, 0.0))\n",
    "            bleu3_score = sentence_bleu([tokens_real],tokens_pred, weights=(0.0, 0.0, 1.0, 0.0))\n",
    "            bleu4_score = sentence_bleu([tokens_real],tokens_pred, weights=(0.0, 0.0, 0.0, 1.0))\n",
    "            bleuA_score = sentence_bleu([tokens_real], tokens_pred, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "        bleu1_sum += bleu1_score\n",
    "        bleu2_sum += bleu2_score\n",
    "        bleu3_sum += bleu3_score\n",
    "        bleu4_sum += bleu4_score\n",
    "        bleuA_sum += bleuA_score \n",
    "\n",
    "    output = 'BLEU_[A-1-2-3-4]: {}/{}/{}/{}/{}'.format(\n",
    "        round(bleuA_sum/len(reference_list), 3) * 100,\n",
    "        round(bleu1_sum/len(reference_list), 3) * 100, \n",
    "        round(bleu2_sum/len(reference_list), 3) * 100, \n",
    "        round(bleu3_sum/len(reference_list), 3) * 100,\n",
    "        round(bleu4_sum/len(reference_list), 3) * 100\n",
    "    )\n",
    "        \n",
    "    filename.write('[TOKENS {}]: {}\\n'.format(i,output))\n",
    "    \n",
    "def levenshtein(seq1, seq2):\n",
    "    \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "                \n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerfectPrediction(predictions_file, target_file):\n",
    "\n",
    "    perfect_pred = {}\n",
    "\n",
    "\n",
    "    target = open(target_file,'r')\n",
    "    target_list =  target.readlines()\n",
    "\n",
    "    for i in range(1,16):\n",
    "\n",
    "        perfect_pred[i] = 0\n",
    "\n",
    "        with open(predictions_file) as fread:\n",
    "\n",
    "            data = fread.readlines()\n",
    "\n",
    "            for (ref,pred) in zip(target_list,data):\n",
    "\n",
    "                pred = pred.strip().lower().split()\n",
    "                pred = pred[0:i]\n",
    "\n",
    "                ref = ref.strip().lower().split()\n",
    "                ref = ref[0:i]\n",
    "\n",
    "                if len(ref)>=i and len(pred)>=i:\n",
    "                    if ''.join(pred) == ''.join(ref):\n",
    "                        perfect_pred[i]+=1\n",
    "\n",
    "            len_tokens_subset = len([item.strip() for item in target_list if len(item.split())>=i ])\n",
    "            perfect_pred[i] = (perfect_pred[i], len_tokens_subset)\n",
    "            \n",
    "    return perfect_pred\n",
    "\n",
    "\n",
    "\n",
    "def feasibleBleuOnly(predictions_file, target_file, task='javadoc'):\n",
    "    \n",
    "    if task=='overall':\n",
    "        \n",
    "        references_list = target_file\n",
    "        candidates_list = predictions_file\n",
    "        \n",
    "        for i in range(4,16):\n",
    "\n",
    "            references = []\n",
    "            candidates = []\n",
    "            \n",
    "            for (ref,pred) in zip(references_list,candidates_list):\n",
    "                \n",
    "                if len(ref.split())>=i:\n",
    "                \n",
    "                    pred = pred.strip().lower()\n",
    "                    ref = ref.strip().lower()\n",
    "                    references.append(ref)\n",
    "                    candidates.append(pred)\n",
    "            \n",
    "            filename  = open('BLEU_result_{}.txt'.format(task),'a+')\n",
    "            computeBleu1_to_4(references, candidates,filename, i)\n",
    "            filename.close()\n",
    "            \n",
    "    else:\n",
    "        target = open(target_file,'r')\n",
    "        target_list =  target.readlines()\n",
    "\n",
    "        for i in range(4,16):\n",
    "\n",
    "            with open(predictions_file) as fread:\n",
    "\n",
    "                data = fread.readlines()\n",
    "\n",
    "                references = []\n",
    "                candidates = []\n",
    "\n",
    "                for (ref,pred) in zip(target_list,data):\n",
    "\n",
    "                    if len(ref.split())>=i:\n",
    "\n",
    "                        pred = pred.strip().lower()\n",
    "                        ref = ref.strip().lower()\n",
    "                        references.append(ref)\n",
    "                        candidates.append(pred)\n",
    "\n",
    "                filename  = open('BLEU_result_{}.txt'.format(task),'a+')\n",
    "                computeBleu1_to_4(references, candidates,filename, i)\n",
    "                filename.close()\n",
    "\n",
    "                \n",
    "def levenshteinOverList(predictions_file, references_file , task='javadoc'):\n",
    "    \n",
    "    if task=='overall':\n",
    "        target_list = references_file\n",
    "        data = predictions_file\n",
    "    \n",
    "    else:\n",
    "        p = open(predictions_file,'r')\n",
    "        data = p.readlines()\n",
    "\n",
    "        r = open(references_file,'r')\n",
    "        target_list = r.readlines()\n",
    "        \n",
    "    references = {}\n",
    "    candidates = {}\n",
    "    lev_list = {}\n",
    "    \n",
    "    for i in range(1,16):\n",
    "        references[i]=[]\n",
    "        candidates[i]=[]\n",
    "        lev_list[i]=0\n",
    "    \n",
    "    for i in range(1,16):\n",
    "\n",
    "        for (ref,pred) in zip(target_list,data):\n",
    "            \n",
    "            target_lev = len(ref.strip().split())\n",
    "            \n",
    "            if target_lev >=i:\n",
    "                \n",
    "                pred = pred.strip().lower().split()[0:i]\n",
    "                ref = ref.strip().lower().split()[0:i]\n",
    "                references[i].append(ref)\n",
    "                candidates[i].append(candidates)\n",
    "                lev_list[i]+=levenshtein(ref, pred)\n",
    "                \n",
    "    for i in range(1,16):\n",
    "        \n",
    "        filename  = open('LEV_result_{}.txt'.format(task),'a+')\n",
    "        lev = lev_list[i]\n",
    "        output = 'LEV: {}'.format(round(lev/len(references[i]),3))\n",
    "        print('[{}] len of references: {}'.format(i,len(references[i])))\n",
    "        filename.write('[TOKENS {}]: {}\\n'.format(i,output))\n",
    "        filename.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### PERFECT PREDICTIONS #######\n",
    "\n",
    "\n",
    "####### Test set ############\n",
    "\n",
    "# path_to_predictions_jdoc = \n",
    "# path_to_targets_jdoc = \n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "####### Hyperparameter #######\n",
    "\n",
    "# path_to_predictions_jdoc = \n",
    "# path_to_targets_jdoc = \n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "hp_num = 0\n",
    "hp_den = 0\n",
    "\n",
    "pred_javadoc = computePerfectPrediction(path_to_predictions_jdoc, path_to_targets_jdoc)\n",
    "perfect_predictions_javadoc = {}\n",
    "for i in range(1,16):        \n",
    "    numbers, len_data = pred_javadoc[i]\n",
    "    percentage = (numbers / len_data) * 100\n",
    "    print('[@{} tokens]: Perfect Javadoc: {}% ({}/{})'.format(i, percentage, numbers, len_data))\n",
    "    perfect_predictions_javadoc[i] = {'percentage':percentage, '#perfect':numbers, '#tokens':len_data}\n",
    "\n",
    "    #hp_num += numbers\n",
    "    #hp_den += len_data\n",
    "\n",
    "# print('javadoc hp results: {}'.format((hp_num/hp_den)*100))\n",
    "\n",
    "print('\\n\\n******************************************************************\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "####### Test set ############\n",
    "\n",
    "# path_to_predictions_inside = \n",
    "# path_to_targets_inside = \n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "####### Hyperparameter #######\n",
    "\n",
    "# path_to_predictions_inside = \n",
    "# path_to_targets_inside = \n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "pred_inside = computePerfectPrediction(path_to_predictions_inside, path_to_targets_inside)\n",
    "\n",
    "hp_num = 0\n",
    "hp_den = 0\n",
    "\n",
    "perfect_predictions_inside = {}\n",
    "\n",
    "for i in range(1,16):        \n",
    "    \n",
    "    numbers, len_data = pred_inside[i]\n",
    "    percentage = (numbers / len_data) * 100\n",
    "    print('[@{} tokens]: Perfect Inside: {}% ({}/{})'.format(i, percentage, numbers, len_data))\n",
    "    perfect_predictions_inside[i] = {'percentage':percentage, '#perfect':numbers, '#tokens':len_data}\n",
    "    \n",
    "    #hp_num += numbers\n",
    "    #hp_den += len_data\n",
    "\n",
    "# print('inside hp results: {}'.format((hp_num/hp_den)*100))\n",
    "    \n",
    "print('\\n\\n******************************************************************\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,16):\n",
    "    \n",
    "    javadoc_item = perfect_predictions_javadoc[i]\n",
    "    numbers_javadoc = javadoc_item['#perfect']\n",
    "    len_data_javadoc = javadoc_item['#tokens']\n",
    "    \n",
    "    inside_item = perfect_predictions_inside[i]\n",
    "    numbers_inside = inside_item['#perfect']\n",
    "    len_data_inside = inside_item['#tokens']\n",
    "        \n",
    "    percentage = ( (numbers_javadoc + numbers_inside) / (len_data_javadoc + len_data_inside) * 100 )\n",
    "    \n",
    "    \n",
    "    print('[@{} tokens]: Perfect Overall: {}% ({}/{})'.format(i, percentage, numbers_inside+numbers_javadoc, \n",
    "                                                              len_data_javadoc+len_data_inside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### BLEU #####\n",
    "\n",
    "references_overall = []\n",
    "candidates_overall = []\n",
    "\n",
    "with open(path_to_predictions_inside,'r') as fread:\n",
    "    for item in fread.readlines():\n",
    "        candidates_overall.append(item.strip().lower())\n",
    "\n",
    "with open(path_to_targets_inside,'r') as fread:\n",
    "    for item in fread.readlines():\n",
    "        references_overall.append(item.strip().lower())\n",
    "        \n",
    "with open(path_to_predictions_jdoc,'r') as fread:\n",
    "    for item in fread.readlines():\n",
    "        candidates_overall.append(item.strip().lower())\n",
    "\n",
    "with open(path_to_targets_jdoc,'r') as fread:\n",
    "    for item in fread.readlines():\n",
    "        references_overall.append(item.strip().lower())\n",
    "        \n",
    "\n",
    "feasibleBleuOnly(path_to_predictions_inside, path_to_targets_inside, 'inside')\n",
    "feasibleBleuOnly(path_to_predictions_jdoc, path_to_targets_jdoc, 'javadoc')\n",
    "feasibleBleuOnly(candidates_overall, references_overall, 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### LEVENSHTEIN ######\n",
    "\n",
    "levenshteinOverList(path_to_predictions_inside, path_to_targets_inside, 'inside')\n",
    "levenshteinOverList(path_to_predictions_jdoc, path_to_targets_jdoc, 'javadoc')\n",
    "levenshteinOverList(candidates_overall, references_overall, 'overall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
